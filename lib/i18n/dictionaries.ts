import type { Locale } from './config'

const dictionaries = {
  en: {
    hero: {
      headline: 'Prove what happened.',
      subheadline: 'Not what should have happened.',
      description: 'Horizon provides continuous oversight of AI decision behaviour, without influencing execution, and produces defensible evidence for individual AI decisions.',
      clarifier: 'Not monitoring. Not judging outcomes. Not enforcing.',
      microLine: 'Built for scrutiny, not demos.',
      primaryCTA: 'Request a briefing',
      secondaryCTA: 'Read the assurance philosophy',
    },
    problem: {
      title: 'The Problem',
      subtitle: 'The missing capability in AI systems today',
      paragraph1: 'Modern AI systems increasingly support or produce consequential decisions.\nWhen those systems are observed in operation, teams rely on dashboards, metrics, and alerts to understand behaviour in real time. This visibility is necessary, but it is not sufficient.',
      paragraph2: 'When a specific decision is examined, the question changes:\nWhat exactly happened in this case?',
      paragraph3: 'Most organizations can describe:',
      list1: [
        'how systems behave on average',
        'what controls and policies exist',
        'what current indicators show',
      ],
      paragraph4: 'They often cannot demonstrate a single decision with stable, examinable facts.\nWhen challenged, teams reconstruct context from logs, configurations, and memory.',
    },
    consequence: {
      title: 'The Consequence of Missing Proof',
      paragraph1: 'When factual proof is missing:',
      list: [
        'oversight relies on interpretation',
        'incidents trigger manual reconstruction',
        'audits depend on narrative coherence',
      ],
      paragraph2: 'A decision can appear compliant and still be indefensible if it cannot be substantiated.\nThis gap is rarely visible during normal operations.\nIt becomes critical under scrutiny.',
    },
    whatIs: {
      title: 'What Horizon Is',
      paragraph1: 'Horizon is an assurance capability designed to operate alongside AI systems without influencing their execution.\nIt provides continuous oversight of system behaviour while preserving factual evidence about individual decisions.',
      paragraph2: 'Horizon does not guide, block, or optimize decisions.\nIt does not determine whether a decision is correct or acceptable.\nIt exists to make behaviour examinable, both during operation and under later scrutiny.',
    },
    produces: {
      title: 'What Horizon Produces',
      paragraph1: 'For each AI-supported decision, Horizon ensures the existence of a decision-level assurance artefact.',
      paragraph2: 'This artefact is designed to:',
      list: [
        'anchor discussions in facts rather than interpretation',
        'remain usable beyond the operational context',
        'support independent examination',
      ],
      paragraph3: 'The artefact is present before any incident, audit, or dispute.\nEvidence that must be assembled later is no longer evidence.',
      paragraph4: 'The assurance artefact captures the factual elements necessary to reconstruct what occurred in a specific decision, without interpretation or post-processing.\nIt remains usable independently of Horizon.',
      paragraph5: 'Horizon does not assemble evidence.\nIt ensures that evidence exists.',
    },
    evidenceEval: {
      title: 'Evidence and Evaluation',
      paragraph1: 'Horizon is grounded in a strict separation.',
      paragraph2: 'Evidence describes what actually occurred.\nEvaluation provides signals to support human judgment.',
      paragraph3: 'Visibility and evaluation evolve over time.\nEvidence remains stable.',
      paragraph4: 'Horizon never replaces human judgment.\nIt ensures that judgment can rely on facts.',
      tagline: 'Signals suggest. Evidence proves.',
    },
    notIs: {
      title: 'What Horizon Is Not',
      paragraph1: 'To avoid ambiguity, Horizon is explicitly not:',
      list: [
        'a monitoring platform',
        'a performance or quality evaluator',
        'an explainability interface',
        'a runtime control or guardrail',
        'a decision engine',
        'a governance dashboard',
      ],
      paragraph2: 'Horizon does not intervene in generation.\nIt observes, preserves, and attests.',
      paragraph3: 'Horizon cannot be replicated by augmenting logs, adding explanations, or reconstructing decisions after the fact.',
    },
    relationship: {
      title: 'Relationship to Existing Tooling',
      paragraph1: 'Operational tools provide visibility, alerts, and control during execution.\nHorizon adds a different capability.',
      paragraph2: 'It ensures that what happens at runtime can later be examined as evidence, without relying on dashboards, configurations, or vendor access.',
      tagline1: 'Visibility is continuous.',
      tagline2: 'Defensibility is permanent.',
    },
    assurance: {
      title: 'Assurance Properties',
      paragraph1: 'Assurance produced through Horizon is designed to be:',
      list: [
        'scoped to individual decisions',
        'consistent over time',
        'interpretable without proprietary context',
        'independently verifiable without the Horizon platform',
        'suitable for audit, regulatory review, or legal scrutiny',
      ],
      paragraph2: 'Interpretation does not depend on configuration or tuning.',
    },
    deployment: {
      title: 'Deployment and Trust Boundaries',
      paragraph1: 'Horizon operates within the organization\'s trust boundary.\nThe organization retains control over:',
      list: [
        'its systems',
        'its data',
        'its assurance material',
      ],
      paragraph2: 'Horizon does not require ongoing access to interpret or validate evidence.\nEvidence ownership remains with the organization.',
      paragraph3: 'Horizon does not trigger mitigation.\nIt enables informed human response.',
    },
    users: {
      title: 'Intended Users',
      paragraph1: 'Horizon is designed for teams responsible for oversight and accountability when AI decisions matter:',
      list: [
        'Risk and Compliance',
        'Internal Audit',
        'AI Governance',
        'Engineering teams operating AI systems at scale',
      ],
      paragraph2: 'Horizon creates a shared factual substrate across these functions.\nIt is built for environments where decisions may be challenged.',
    },
    when: {
      title: 'When Horizon Becomes Necessary',
      paragraph1: 'Horizon is valuable before anything goes wrong.\nIt is valuable during normal operation and critical when scrutiny arises.',
      paragraph2: 'It becomes necessary when:',
      list: [
        'individual AI decisions can be challenged',
        'regulatory or legal review is expected',
        'post-incident analysis must rely on facts',
        'explanations must remain defensible over time',
      ],
      paragraph3: 'If a decision matters, proof must already exist.',
    },
    philosophy: {
      title: 'Philosophy',
      paragraph1: 'Horizon enables organizations to adopt AI systems without relying on fragile reconstructions or retrospective narratives.',
      tagline: 'Signals suggest. Evidence proves.',
    },
    cta: {
      title: 'Call to Action',
      paragraph1: 'Learn how Horizon fits into an AI assurance strategy focused on accountability under scrutiny.',
      primaryCTA: 'Request a briefing',
      secondaryCTA: 'Discuss audit and regulatory use cases',
    },
    contact: {
      title: 'Email',
      intro: 'Our email:',
      copied: 'Copied',
      copy: 'Copy email',
      mailto: 'Open in my mail client',
      note: 'You can paste this email into your mail application.',
    },
  },
  fr: {
    hero: {
      headline: "Prouver ce qui s'est passé.",
      subheadline: "Pas ce qui aurait dû se passer.",
      description: "Horizon assure une surveillance continue des mécanismes décisionnels de l'IA, sans interférer avec son exécution, et produit des preuves tangibles pour chaque décision individuelle.",
      clarifier: "Ni monitoring. Ni jugement des décisions. Ni contrainte.",
      microLine: "Conçu pour l'audit, pas pour la démonstration.",
      primaryCTA: 'Demander une présentation',
      secondaryCTA: "Lire notre vision de l'assurance",
    },
    problem: {
      title: 'Le problème',
      subtitle: "La fonction manquante dans les systèmes d'IA actuels",
      paragraph1: "Les systèmes d'IA soutiennent de plus en plus des décisions à fort enjeu.\nEn phase d'exploitation, les équipes s'appuient sur des tableaux de bord et des indicateurs pour comprendre les comportements en temps réel. Cette visibilité est nécessaire, mais insuffisante.",
      paragraph2: "Lorsqu'une décision précise est examinée, la question change :\nQue s'est-il exactement passé dans ce cas précis ?",
      paragraph3: 'La plupart des organisations peuvent décrire :',
      list1: [
        'le comportement moyen du système',
        'les contrôles et politiques en place',
        'les indicateurs à un instant T',
      ],
      paragraph4: "Elles sont souvent incapables de justifier une décision unique par des faits stables et vérifiables.\nEn cas de contrôle, les équipes reconstituent le contexte à partir de journaux d'événements, de configurations et de souvenirs.",
    },
    consequence: {
      title: "Les conséquences d'une absence de preuve",
      paragraph1: "En l'absence de preuves factuelles :",
      list: [
        "la supervision repose sur l'interprétation",
        'les incidents imposent une reconstitution manuelle',
        'les audits dépendent de la cohérence des récits',
      ],
      paragraph2: "Une décision peut paraître conforme tout en étant impossible à justifier si elle n'est pas étayée.\nCette lacune est rarement visible en fonctionnement normal, mais devient critique lors d'un audit.",
    },
    whatIs: {
      title: "Ce qu'est Horizon",
      paragraph1: "Horizon est un dispositif d'assurance conçu pour fonctionner en parallèle des systèmes d'IA sans influencer leur exécution.\nIl assure une surveillance continue tout en préservant les preuves factuelles des décisions individuelles.",
      paragraph2: "Horizon ne guide, ne bloque, ni n'optimise les décisions.\nIl ne juge pas si une décision est correcte. Son rôle est de rendre le comportement vérifiable, tant en exploitation qu'en cas de contrôle ultérieur.",
    },
    produces: {
      title: 'Ce que produit Horizon',
      paragraph1: "Pour chaque décision assistée par l'IA, Horizon garantit la création d'un élément d'assurance spécifique.",
      paragraph2: "Cet élément est conçu pour :",
      list: [
        "ancrer les discussions dans les faits plutôt que dans l'interprétation",
        'rester exploitable en dehors du contexte opérationnel',
        'permettre un examen indépendant',
      ],
      paragraph3: "Cet élément est disponible avant tout incident ou litige.\nUne preuve que l'on doit reconstituer après coup n'est plus une preuve.",
      paragraph4: "L'élément d'assurance capture les faits nécessaires pour reconstituer une décision donnée, sans interprétation ni traitement ultérieur.\nIl reste utilisable indépendamment d'Horizon.",
      paragraph5: "Horizon ne compile pas de preuves.\nIl garantit leur existence.",
    },
    evidenceEval: {
      title: 'Preuve et évaluation',
      paragraph1: 'Horizon repose sur une séparation stricte.',
      paragraph2: "La preuve décrit ce qui s'est réellement produit.\nL'évaluation fournit les signaux nécessaires au jugement humain.",
      paragraph3: "La visibilité et l'évaluation évoluent avec le temps.\nLa preuve, elle, reste immuable.",
      paragraph4: "Horizon ne remplace jamais le jugement humain.\nIl garantit que ce jugement repose sur des faits.",
      tagline: 'Les signaux suggèrent. La preuve établit.',
    },
    notIs: {
      title: "Ce que Horizon n'est pas",
      paragraph1: 'Pour éviter toute ambiguïté, Horizon n’est pas :',
      list: [
        'une plateforme de surveillance (monitoring)',
        'un outil de mesure de performance ou de qualité',
        'une interface d’explicabilité',
        "un dispositif de contrôle en temps réel ou garde-fou",
        'un moteur de décision',
        'un tableau de bord de gouvernance',
      ],
      paragraph2: "Horizon n'intervient pas dans la génération.\nIl observe, préserve et atteste.",
      paragraph3: "Horizon ne peut être remplacé par un simple enrichissement des journaux (logs) ou par une reconstitution a posteriori.",
    },
    relationship: {
      title: "Complémentarité avec l'existant",
      paragraph1: "Les outils opérationnels offrent visibilité et contrôle pendant l'exécution.\nHorizon apporte une dimension différente.",
      paragraph2: "Il garantit que les événements survenus lors de l'exécution peuvent être examinés comme des preuves, sans dépendre des tableaux de bord ou des accès fournisseurs.",
      tagline1: 'La visibilité est continue.',
      tagline2: 'La validité des preuves est permanente.',
    },
    assurance: {
      title: "Propriétés de l'assurance",
      paragraph1: "L'assurance produite par Horizon est conçue pour être :",
      list: [
        'spécifique à chaque décision',
        'cohérente dans le temps',
        'interprétable sans contexte propriétaire',
        'vérifiable sans la plateforme Horizon',
        'adaptée aux audits et aux contrôles réglementaires ou juridiques',
      ],
      paragraph2: "L'interprétation ne dépend d'aucun réglage ou ajustement.",
    },
    deployment: {
      title: 'Déploiement et périmètre de confiance',
      paragraph1: "Horizon opère au sein du périmètre de confiance de l'organisation.\nCelle-ci conserve la maîtrise totale :",
      list: [
        'de ses systèmes',
        'de ses données',
        "de ses éléments d'assurance",
      ],
      paragraph2: "Horizon ne requiert aucun accès permanent pour valider les preuves.\nLa propriété des preuves appartient exclusivement à l'organisation.",
      paragraph3: "Horizon ne déclenche pas de mesures de correction.\nIl permet une intervention humaine éclairée.",
    },
    users: {
      title: 'Utilisateurs visés',
      paragraph1: "Horizon est conçu pour les équipes responsables de la supervision et de la redevabilité :",
      list: [
        'Risques et Conformité',
        'Audit interne',
        'Gouvernance de l’IA',
        "Équipes d'ingénierie gérant l'IA à grande échelle",
      ],
      paragraph2: "Horizon crée un socle factuel commun entre ces fonctions.\nIl est conçu pour les contextes où les décisions peuvent être contestées.",
    },
    when: {
      title: 'Quand Horizon devient indispensable',
      paragraph1: "Horizon est utile dès la mise en service.\nIl est précieux au quotidien et devient critique lors d'un contrôle.",
      paragraph2: 'Il devient nécessaire lorsque :',
      list: [
        'des décisions d’IA peuvent être contestées',
        'un audit réglementaire ou juridique est attendu',
        "l'analyse après incident doit reposer sur des faits",
        'les justifications doivent rester solides dans le temps',
      ],
      paragraph3: 'Si une décision a de l’importance, la preuve doit déjà exister.',
    },
    philosophy: {
      title: 'Philosophie',
      paragraph1: "Horizon permet d'adopter l'IA sans dépendre de reconstitutions fragiles ou de récits rétrospectifs.",
      tagline: 'Les signaux suggèrent. La preuve établit.',
    },
    cta: {
      title: "Appel à l'action",
      paragraph1: "Découvrez comment Horizon s'intègre dans une stratégie d'assurance IA axée sur la responsabilité.",
      primaryCTA: 'Demander une présentation',
      secondaryCTA: "Échanger sur les cas d'usage audit et réglementaire",
    },
    contact: {
      title: 'E-mail',
      intro: 'Notre adresse e-mail :',
      copied: 'Copié',
      copy: "Copier l'adresse",
      mailto: 'Ouvrir dans ma messagerie',
      note: 'Vous pouvez coller cette adresse dans votre logiciel de messagerie.',
    },
  },
}

export async function getDictionary(locale: Locale) {
  return dictionaries[locale]
}
