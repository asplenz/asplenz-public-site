[Version EN]

**New landing page — Horizon**

**Hero**
When accountability is questioned, proof must already exist.
Horizon is a system of record for critical decisions.
It captures decisions as immutable facts — before they need to be explained.
Human. Automated. AI-driven.

**The reality organizations face**
Every organization makes decisions that carry risk.
Some are human.
Some are automated.
Some are delegated to AI systems.
Most are not provable.
When something goes wrong, teams rely on:

* logs never designed for accountability
* emails written after the fact
* narratives reconstructed under pressure

That is not proof.
That is exposure.

**What breaks when proof is missing**

* Audits turn into investigations
* Individuals become personally exposed
* Decisions are judged on explanations, not facts
* Accountability becomes fragile
At that point, it’s already too late.

**What Horizon does**
Horizon records decisions as facts.
Not workflows.
Not policies.
Not explanations.
Decisions.

Each decision is:

* explicitly declared
* time-stamped
* sealed
* independently verifiable

Once recorded, it cannot be altered, rewritten, or disputed.

**What counts as a decision**
A decision exists when an outcome can affect reality.
For example:

* an approval or rejection
* an authorization or override
* an acceptance of risk
* a system-triggered action

Whether the decision comes from:

* a human
* an automated system
* an AI system

Horizon records the fact that it happened — and under whose authority.

**Decisions are not judged. They are proven.**
Horizon does not decide.
Horizon does not validate.
Horizon does not enforce rules.
It preserves:

* what was decided
* by whom or by which system
* when
* under which declared context
* with which justification or authority

Neutrality is what makes the proof defensible.

**Built for AI accountability — not limited to AI**
AI systems amplify risk:

* decisions scale instantly
* context disappears quickly
* responsibility becomes blurred

Horizon provides definitive proof for:

* production go / no-go approvals
* acceptance of residual AI risk
* model and data validation sign-offs
* automated approvals and overrides
* post-incident decisions

This enables human accountability — even when decisions are automated.

**Incident-ready by design**
Decisions exist:

* before incidents
* during incidents
* after incidents

Horizon links decisions to incidents when needed, and preserves:

* timelines
* snapshots
* complete proof packages

When accountability is questioned, the facts are already there.

**What Horizon replaces**

* Email approvals → sealed decision records
* Tickets and comments → attributable decisions
* Static PDFs → decision timelines
* Manual reconstruction → immediate proof

Less stress.
Less exposure.
More certainty.

**Who Horizon is for**

* **Legal & Compliance**: Defend decisions with facts, not narratives.
* **Risk & AI Governance**: Demonstrate accountability without relying on fragile systems.
* **Audit**: Rely on independent, verifiable evidence.
* **Executives**: Reduce exposure as automation scales.

**What Horizon is not**

* Not a decision engine
* Not a policy engine
* Not a governance platform
* Not an AI explainability tool
Horizon exists after decisions are made, not before.

**One simple question**
Which decision would you need to prove tomorrow?
Horizon starts there.

**Talk to an expert**

**Footer**
Systems act.
People decide.
Horizon proves.

---

[Version FR]

**Nouvelle page de présentation — Horizon**

**Hero**
Quand la responsabilité est mise en cause, la preuve doit déjà exister.
Horizon est le système de référence pour les décisions critiques.
Il capture les décisions sous forme de faits immuables — avant même qu'elles n'aient besoin d'être justifiées.
Humaines. Automatisées. Pilotées par l'IA.

**La réalité des organisations**
Toute organisation prend des décisions porteuses de risques.
Certaines sont humaines.
Certaines sont automatisées.
D'autres sont déléguées à des systèmes d'IA.
La plupart ne sont pas prouvables.
En cas de problème, les équipes s'appuient sur :

* des logs qui n'ont jamais été conçus pour établir des responsabilités
* des emails rédigés après coup
* des récits reconstitués sous pression

Ce ne sont pas des preuves.
C'est une exposition au risque.

**Les conséquences d'une preuve manquante**

* Les audits se transforment en enquêtes
* Les individus se retrouvent exposés personnellement
* Les décisions sont jugées sur des explications, pas sur des faits
* La chaîne de responsabilité devient fragile
À ce stade, il est déjà trop tard.

**Ce que fait Horizon**
Horizon enregistre les décisions comme des faits.
Pas des workflows.
Pas des procédures.
Pas des explications.
Des décisions.

Chaque décision est :

* explicitement déclarée
* horodatée
* scellée
* vérifiable de manière indépendante

Une fois enregistrée, elle ne peut être ni altérée, ni réécrite, ni contestée.

**Ce qui constitue une décision**
Une décision existe dès lors qu'un résultat peut impacter la réalité.
Par exemple :

* une approbation ou un rejet
* une autorisation ou un passage outre (*override*)
* une acceptation de risque
* une action déclenchée par un système

Que la décision vienne :

* d'un humain
* d'un système automatisé
* d'un système d'IA

Horizon enregistre le fait qu'elle a eu lieu — et sous quelle autorité.

**Les décisions ne sont pas jugées. Elles sont prouvées.**
Horizon ne décide pas.
Horizon ne valide pas.
Horizon n'impose pas de règles.
Il préserve :

* ce qui a été décidé
* par qui ou par quel système
* quand
* dans quel contexte déclaré
* avec quelle justification ou autorité

C’est cette neutralité qui rend la preuve opposable.

**Conçu pour la responsabilité de l'IA — mais pas seulement**
Les systèmes d'IA amplifient les risques :

* les décisions passent à l'échelle instantanément
* le contexte s'efface rapidement
* la responsabilité devient floue

Horizon fournit une preuve irréfutable pour :

* les validations de mise en production (go / no-go)
* l'acceptation des risques résiduels liés à l'IA
* les signatures de validation de modèles et de données
* les approbations et contournements automatisés
* les décisions post-incident

Cela garantit une responsabilité humaine — même lorsque les décisions sont automatisées.

**Prêt pour l'incident, par conception**
Les décisions existent :

* avant l'incident
* pendant l'incident
* après l'incident

Horizon lie les décisions aux incidents si nécessaire et préserve :

* les chronologies des faits
* des captures instantanées (*snapshots*)
* des dossiers de preuve complets

Quand la responsabilité est questionnée, les faits sont déjà là.

**Ce que Horizon remplace**

* Approbations par email → Registres de décisions scellés
* Tickets et commentaires → Décisions attribuables
* PDF statiques → Chronologies décisionnelles
* Reconstitution manuelle → Preuve immédiate

Moins de stress.
Moins d'exposition.
Plus de certitude.

**À qui s'adresse Horizon**

* **Juridique & Conformité** : Défendez vos décisions avec des faits, pas des récits.
* **Risques & Gouvernance de l'IA** : Démontrez votre responsabilité sans dépendre de systèmes fragiles.
* **Audit** : Appuyez-vous sur des preuves indépendantes et vérifiables.
* **Dirigeants** : Réduisez votre exposition à mesure que l'automatisation se généralise.

**Ce que Horizon n'est pas**

* Ni un moteur de décision
* Ni un gestionnaire de règles
* Ni une plateforme de gouvernance
* Ni un outil d'explicabilité de l'IA
Horizon intervient après la prise de décision, pas avant.

**Une question simple**
Quelle décision devriez-vous être capable de prouver demain ?
Horizon commence là.

**Parler à un expert**

**Pied de page**
Les systèmes agissent.
Les humains décident.
Horizon prouve.