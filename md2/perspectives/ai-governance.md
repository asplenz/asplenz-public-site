[VERSION EN]

### **AI & Data Governance Perspective**

For teams responsible for long-term traceability of automated systems.

**The reality of your role**

You govern systems that evolve by design.

Models are retrained. Inputs are replaced. Outputs are overwritten or aggregated. Decision paths disappear as systems optimize themselves.

Your challenge is not performance. It is preserving stable factual reference points in systems built to change.

**Where Horizon fits**

Horizon provides a neutral infrastructure for sealing declared facts.

It does not evaluate models. It does not explain decisions. It does not enforce governance rules. It records declared inputs, outputs, or observations at a specific moment in time and seals them independently from learning systems.

Horizon exists to ensure that facts do not drift as systems evolve.

**What Horizon provides to AI & Data Governance**

* Sealed records of declared inputs or outputs
* Independent timestamps at declaration time
* Append-only integrity outside training pipelines
* Evidence that remains verifiable after model updates
* Nothing more.

**What Horizon does not do**

* Does not explain model behavior
* Does not ensure fairness or bias mitigation
* Does not enforce regulatory compliance
* Does not monitor performance or drift

Horizon does not govern AI. It preserves facts around it.

**After an incident or review, you can establish**

Using Horizon, you can verify:

* What data or output was declared
* When it was sealed
* Whether it was altered afterward

Even if models, datasets, or pipelines have since changed.

**Why this matters for AI & Data Governance**

AI systems rewrite their own past. Logs are pruned. Training data is replaced. Outputs are no longer reproducible.

Horizon introduces fixed reference points that remain stable while systems evolve. This allows governance and oversight to operate on facts, not on reconstructed or simulated histories.

**What Horizon changes**

Before Horizon:

* AI traces drift
* Historical outputs are lost
* Governance relies on approximations

With Horizon:

* Facts are sealed
* Integrity is verifiable
* Oversight starts from stable records

**Next**

**View how facts are sealed**
This example shows how declared AI-related facts are sealed, timestamped, and appended to an immutable chain, independent of model lifecycle.

**Editorial note (do not display)**
This page intentionally avoids: claims of explainability, promises of compliance with specific AI regulations, operational control of AI systems. It exists to position Horizon as a factual anchor, not a governance engine.

---

[VERSION FR]

### **Perspective Gouvernance de l'IA et des Données**

Pour les équipes responsables de la traçabilité à long terme des systèmes automatisés.

**La réalité de votre rôle**

Vous gouvernez des systèmes qui évoluent par conception.

Les modèles sont réentraînés. Les entrées sont remplacées. Les sorties sont écrasées ou agrégées. Les chemins de décision disparaissent à mesure que les systèmes s'optimisent eux-mêmes.

Votre défi n'est pas la performance. Il s'agit de préserver des points de référence factuels stables dans des systèmes conçus pour changer.

**Où Horizon se situe**

Horizon fournit une infrastructure neutre pour sceller les faits déclarés.

Il n'évalue pas les modèles. Il n'explique pas les décisions. Il n'impose pas de règles de gouvernance. Il enregistre les entrées, les sorties ou les observations déclarées à un instant précis et les scelle indépendamment des systèmes d'apprentissage.

Horizon existe pour garantir que les faits ne dérivent pas à mesure que les systèmes évoluent.

**Ce que Horizon apporte à la Gouvernance de l'IA et des Données**

* Des enregistrements scellés des entrées ou sorties déclarées
* Des horodatages indépendants au moment de la déclaration
* Une intégrité append-only en dehors des pipelines d'entraînement
* Une preuve qui reste vérifiable après la mise à jour des modèles
* Rien de plus.

**Ce que Horizon ne fait pas**

* N'explique pas le comportement du modèle
* N'assure pas l'équité ou l'atténuation des biais
* N'impose pas la conformité réglementaire
* Ne surveille pas la performance ou la dérive

Horizon ne gouverne pas l'IA. Il préserve les faits qui l'entourent.

**Après un incident ou une révision, vous pouvez établir**

En utilisant Horizon, vous pouvez vérifier :

* Quelles données ou sorties ont été déclarées
* Quand elles ont été scellées
* Si elles ont été altérées par la suite

Même si les modèles, les jeux de données ou les pipelines ont changé depuis.

**Pourquoi cela compte pour la Gouvernance de l'IA et des Données**

Les systèmes d'IA réécrivent leur propre passé. Les logs sont élagués. Les données d'entraînement sont remplacées. Les sorties ne sont plus reproductibles.

Horizon introduit des points de référence fixes qui restent stables pendant que les systèmes évoluent. Cela permet à la gouvernance et à la surveillance d'opérer sur des faits, et non sur des histoires reconstruites ou simulées.

**Ce que Horizon change**

Avant Horizon :

* Les traces de l'IA dérivent
* Les sorties historiques sont perdues
* La gouvernance repose sur des approximations

Avec Horizon :

* Les faits sont scellés
* L'intégrité est vérifiable
* La surveillance part de registres stables

**Suivant**

**Voir comment les faits sont scellés**
Cet exemple montre comment les faits déclarés liés à l'IA sont scellés, horodatés et ajoutés à une chaîne immuable, indépendamment du cycle de vie du modèle.

**Note éditoriale (ne pas afficher)**
Cette page évite intentionnellement : les affirmations sur l'explicabilité, les promesses de conformité à des réglementations spécifiques sur l'IA, le contrôle opérationnel des systèmes d'IA. Elle existe pour positionner Horizon comme une ancre factuelle, et non comme un moteur de gouvernance.